# Development Plan â€” v0.2

In-progress milestones for kiso v0.2. Continues from v0.1 (all M1â€“M43 complete).

## Principles

- **Agile**: smallest testable increment first, then layer on
- **No dead code**: every line written is immediately reachable and testable
- **Fail loud**: missing config, broken provider, invalid input â†’ clear error, never silent fallback
- **Tested**: every milestone adds tests. `uv run pytest` must pass before moving on.

---

## Milestone 44: Deferred items + polish

Collect all items explicitly deferred during v0.1 development, plus small UX fixes observed in production.

### 44a. worker â€” estrai `search.py` da `loop.py`

**Problema**: M36 prevedeva `kiso/worker/search.py` come modulo dedicato al search handler (analogo a `exec.py` e `skill.py`). La logica Ã¨ invece rimasta in `loop.py`, rompendo la simmetria del package. Il `__init__.py` non esporta nulla di search-related.

**Fix**: estrarre il search handler da `loop.py` in `kiso/worker/search.py`, analogamente a `exec.py` e `skill.py`. Aggiornare `__init__.py` e gli import.

- [x] `kiso/worker/search.py`: nuovo modulo con `_parse_search_args()` e `_search_task()` estratti da `loop.py`
- [x] `kiso/worker/loop.py`: rimosso il parsing inline degli args e la chiamata `run_searcher` diretta; usa `_search_task()`
- [x] `kiso/worker/__init__.py`: esporta `_parse_search_args` e `_search_task`
- [x] `tests/test_worker.py`: aggiornati i patch target da `kiso.worker.loop.run_searcher` a `kiso.worker.search.run_searcher` (17 occorrenze)
- [x] `tests/test_search.py`: 33 unit test isolati per `_parse_search_args` e `_search_task` (boundary max_results, type errors, malformed JSON, warning log, propagazione parametri)

---

### 44b. CLI â€” loader on new line

**Problem**: the "thinking..." spinner appears inline with the last content line instead of on its own line. Visually confusing when the previous output ends without a trailing newline.

**Fix**: ensure the loader/spinner always starts on a fresh line.

- [x] `cli/__init__.py`: `_poll_status` gains `_at_col0: bool = True` parameter; emits `\n` before first frame when `_at_col0=False`
- [x] tests: 2 new cases verify `\n\n\r` (extra newline) vs `\n\r` (no extra newline)

---

### 44c. Fact poisoning â€” `save_learning` content filter

**Context**: during M21 the curator prompt was deemed sufficient to guard against manipulative learnings. Monitor in production whether this holds or whether pre-storage filtering is needed.

- [x] Added `_SENSITIVE_PATTERN` regex + filter in `save_learning()` (keywords: password/passwd/token, hex â‰¥32 chars); returns 0 + logs warning
- [x] 7 unit tests: keyword rejection (case-insensitive), hex threshold, benign acceptance, sentinel preservation

---

### 44d. Verbose mode â€” incremental LLM rendering

**Context**: `append_task_llm_call()` was added in M31 but the worker still batches all LLM call data at task end. Documented as known limitation in `docs/cli.md`.

**Fix**: call `append_task_llm_call()` after each individual LLM call (searcher, exec translator, reviewer, messenger) so verbose panels appear incrementally during task execution.

- [x] `kiso/worker/loop.py`: `_append_calls()` helper added; called after each LLM op (translator, reviewer, messenger, searcher) in all task branches and fast-path
- [x] `llm_calls=` removed from all `update_task_usage` call sites; `_KEEP_LLM_CALLS` sentinel preserves incrementally-appended column
- [x] `docs/cli.md`: removed "Known limitations â€” batch rendering" note
- [x] 5 tests: assert `_append_calls` call count per task type; verify `update_task_usage` called without explicit `llm_calls`

---

### 44e. Post-review hardening â€” M44b/M44c/M44d follow-up

Problemi di alta/media severitÃ  emersi dalla review di M44b+M44d.

#### Alta severitÃ 

- [x] `cli/__init__.py`: docstring completa per `_poll_status()` con spiegazione del parametro `_at_col0`
- [x] `kiso/store.py`: `save_learning()` â€” TypeError su `content=None`; return 0 su stringa vuota/whitespace; docstring aggiornata
- [x] `kiso/worker/loop.py`: `_append_calls()` â€” `try/except Exception` con log.warning; nessun crash del worker per errori di usage tracking
- [x] `kiso/worker/loop.py`: `_fast_path_chat()` â€” `_append_calls()` chiamata anche nel failure path (eccez. messenger)

#### Media severitÃ 

- [x] `tests/test_store.py`: guard None (TypeError), stringa vuota, whitespace, boundary hex 31 chars (accettato) vs 32 chars (rifiutato)
- [x] `tests/test_worker.py`: `_append_calls` handles exception, fast_path failure appends, success vs failure same call_count; retry scenario verifica 5 `_append_calls` (2 tentativi Ã— 2 + 1 msg)
- [x] `tests/test_cli.py`: `\n\n\r` appare esattamente una volta â€” extra newline solo al primo frame, non ai frame successivi

---

### 44f. Admin context â€” session labels on facts

**Context**: M43 implemented strict session scoping for regular users (Option B). Admin users already bypass the filter and receive all facts, but with no indication of which session each fact originated from, making cross-session facts indistinguishable in the planner context.

**Fix**: when building planner context for an admin caller, split facts into two priority tiers:
- **Primary** (`## Known Facts`): facts from the current session + global facts (session IS NULL). Shown without session label â€” these are the most relevant.
- **Background** (`## Context from Other Sessions`): facts from other sessions, annotated with `[session:<name>]`. Available as broader memory if needed.

Non-admin path is unchanged (single `## Known Facts` block, no labels).

- [x] `kiso/brain.py`: `build_planner_messages()` â€” admin path splits `facts` into `primary` and `other`; `_group_by_category()` helper renders both blocks; non-admin uses `primary=facts, other=[]`
- [x] `tests/test_brain.py`: `test_admin_facts_hierarchy` â€” current-session + global facts in `## Known Facts` (no label); other-session fact in `## Context from Other Sessions` with `[session:name]`; current-session fact never carries a label
- [x] `tests/test_brain.py`: `test_non_admin_facts_no_session_labels` â€” non-admin context has no `[session:` and no `## Context from Other Sessions`

---

## Milestone 45: Planner â€” plugin discovery via registry (not web search)

**Problema osservato in produzione**: l'utente chiede "voglio installare connettore discord" e il planner emette `[search] kiso discord connector` (web search) invece di `[exec] curl <registry_url>`. Il reviewer correttamente rigetta il risultato ("sa-mp discord connector", non quello kiso), ma il ciclo Ã¨ sprecato.

**Cause root**:
1. La rule "Prefer search over exec curl/wget for web lookups" nel task type `search` non aveva l'eccezione esplicita per il registry kiso.
2. Le regole MANDATORY sulla discovery via registry erano seppellite in fondo e non collegavano esplicitamente l'eccezione alla rule search.
3. `kiso` non era in `PROBE_BINARIES` â†’ non compariva nella lista "available binaries" del System Environment.

**Fix**:

- [x] `kiso/roles/planner.md`: aggiunta eccezione esplicita nella description del task `search`: "NEVER use search to discover kiso plugins â€” use exec curl on the registry URL instead (see Plugin installation rule below)"
- [x] `kiso/roles/planner.md`: regole MANDATORY unificate e riscritte come "Plugin installation (MANDATORY)": unico blocco che copre discovery (exec curl registry, mai web search) + install + env requirements
- [x] `kiso/sysenv.py`: aggiunto `"kiso"` in testa a `PROBE_BINARIES` â€” il binario appare in "available binaries" se installato, rendendo esplicita la sua disponibilitÃ  al planner
- [x] `tests/test_brain.py`: `test_m45_plugin_install_uses_registry_not_search` â€” verifica che il prompt contenga "NEVER" + "registry" + "web search"
- [x] `tests/test_brain.py`: `test_m45_plugin_install_rule_is_mandatory` â€” verifica che "Plugin installation (MANDATORY)" sia nel prompt
- [x] `tests/test_sysenv.py`: `test_kiso_in_probe_list` â€” verifica che `"kiso"` sia in `PROBE_BINARIES`
- [x] `docs/flow.md`: aggiornate sezioni "Facts" (era "global", ora "session-scoped"), "Planner Context" (aggiunto esempio admin con `## Context from Other Sessions`)
- [x] `docs/security-risks.md`: aggiornate due sezioni obsolete ("Facts are global" â†’ scoping M43 + residual risk per categorie globali)
- [x] `docs/llm-roles.md`: aggiornata tabella contesto ("Facts (global)" â†’ "Facts (session-scoped; admin sees all)")

---

## Milestone 47: Planner/Reviewer â€” qualitÃ  dei piani e correttezza della valutazione

Problemi osservati in produzione durante l'installazione di Discord. Tre difetti distinti che si sono concatenati causando un loop di replan inutile fino al timeout.

---

### 47a. Planner â€” autoconsapevolezza e disambiguazione intent

**Problema**: il planner non sa di essere il cervello di un sistema specifico (Kiso). Si comporta come un task planner generico su OS. Questo causa due difetti concatenati: (1) non distingue tra richieste che riguardano il layer OS e quelle che riguardano il layer Kiso; (2) ha un bias verso l'esecuzione anche quando l'intent Ã¨ ambiguo.

**Causa root**: il prompt inizia con "You are a task planner." â€” nessuna identitÃ , nessun contesto su Kiso, nessuna consapevolezza dei due layer disponibili.

**Soluzione concordata â€” due interventi sul prompt del planner**:

**(1) Autoconsapevolezza** â€” aggiungere in testa al prompt:
- IdentitÃ : il planner Ã¨ il cervello di Kiso, non un planner generico
- Two-layer awareness: ha a disposizione sia comandi OS sia primitive Kiso native (skill, connector, env, memoria); prima di pianificare una soluzione OS, verificare se esiste giÃ  una soluzione Kiso-native. Scoped alla scelta della soluzione, non come preferenza globale assoluta.

**(2) Bias di disambiguazione** â€” invertire il default sulla clarifica:
- Attuale (permissivo): "if unclear, ask" â€” il planner deve giustificare il chiedere
- Nuovo (restrittivo): procedi solo se intent E target sono entrambi non ambigui; altrimenti chiedi
- Una riga sola, nessun caso enumerato; la two-layer awareness Ã¨ il contesto che rende applicabile la regola

- [x] `kiso/roles/planner.md`: aggiunta identity Kiso + two-layer awareness in testa al prompt
- [x] `kiso/roles/planner.md`: regola clarifica invertita â€” "proceed only if unambiguous, else ask"
- [x] `kiso/roles/planner.md`: guida su `expect` task-scoped
- [x] `docs/llm-roles.md`: sezione "Identity and Environment Awareness" aggiunta al Planner
- [x] `docs/llm-roles.md`: campo `expect` aggiornato con nota su scope task
- [x] `tests/test_brain.py`: `TestM47PlannerIdentityAndTwoLayer` â€” 5 test su identity, two-layer, Kiso-native preference, clarification bias, expect scoping

---

### 47b. Reviewer â€” valuta `expect` del task, non il goal del piano

**Problema**: il reviewer usa il Plan Goal come criterio di successo invece dell'`expect` del singolo task. Caso concreto: `apt-get install -f` con output "0 upgraded, 0 installed" (= nessuna dipendenza rotta = successo) Ã¨ stato marcato `replan` perchÃ© "Discord non Ã¨ ancora fully functional" â€” che Ã¨ il goal del piano, non il criterio del task.

**Causa root**: il prompt del reviewer riceve il `Plan Goal` come contesto ma non distingue esplicitamente tra "context" e "success criterion". Il modello tende a unificarli.

**Soluzione concordata â€” due interventi**:

1. **Rinominare** il campo `Plan Goal` â†’ `Plan Context` nel messaggio costruito da `build_reviewer_messages` in `brain.py`. Il nome cambia il frame a livello strutturale: il modello vede un dato coerente con la regola invece di un dato che la contraddice.

2. **Aggiungere una regola** al prompt del reviewer: "Plan Context is background only. The sole success criterion is the task's `expect`." Output "nothing to do" / "0 changes" per comandi di manutenzione Ã¨ successo valido se coerente con l'`expect`.

- [x] `kiso/brain.py`: `build_reviewer_messages` â€” rinominato `## Plan Goal` â†’ `## Plan Context`
- [x] `kiso/roles/reviewer.md`: aggiunta regola "Plan Goal is background context only" + regola su "0 changes"
- [x] `docs/llm-roles.md`: tabella contesto aggiornata ("Plan context (goal) â€” as background"); `goal` output field aggiornato
- [x] `tests/test_brain.py`: `TestM47ReviewerPlanContext` â€” 4 test su label, regola background, sole criterion, zero-changes

---

### 47c. Planner â€” `expect` scoped al piano, non al task

**Problema**: il planner scrive `expect` che descrivono il goal globale del piano invece dell'output atteso del singolo task. Esempio: per `apt-get install -f`, il planner ha scritto `"All dependencies resolved, Discord should be fully functional"` â€” che Ã¨ il goal del piano. Questo causa il problema 47b.

**Causa root**: nessuna istruzione nel prompt del planner su come scrivere `expect` task-scoped. Il planner propaga il goal del piano nell'`expect` di ogni task, invece di descrivere cosa deve produrre/mostrare quel task specifico.

**Nota**: 47c Ã¨ indipendente da 47b e necessario anche dopo il fix del reviewer. Un reviewer correttamente calibrato che ignora il Plan Context valuta comunque l'`expect` letteralmente â€” se l'`expect` dice "Discord should be fully functional", il reviewer Ã¨ costretto a marcare `apt-get install -f` come fallito anche se ha ragione. Il problema Ã¨ a monte: il planner ha scritto l'`expect` sbagliato.

**Soluzione concordata**: aggiungere al prompt del planner una guida esplicita su come scrivere `expect`:
- descrive l'output diretto di questo specifico task, non il goal del piano
- deve essere falsificabile dall'output del task da solo
- per comandi di manutenzione/cleanup (apt-get install -f, git clean, ecc.), "0 changes" Ã¨ un successo valido e va detto esplicitamente nell'expect

- [x] implementato insieme a 47a (`kiso/roles/planner.md` + test `test_planner_prompt_expect_scoping`)

---

### 47d. Worker (exec translator) â€” retry hint ignorato

**Problema**: al retry, il worker ignora l'hint nel Retry Context e ri-traduce letteralmente il `detail` del task originale, producendo lo stesso comando fallito. Nel caso Discord, l'hint diceva "usa `apt install discord`" ma il worker ha riprodotto `apt-get install -f` perchÃ© il `detail` del task lo specificava.

**Causa root**: il prompt del worker non menziona il Retry Context. Il worker non sa che in caso di retry l'hint dovrebbe guidare la traduzione alternativa.

**Soluzione concordata**: aggiungere al prompt del worker che in presenza di Retry Context con hint, l'hint ha prioritÃ  sulla traduzione letterale del `detail`. Il `detail` rimane contesto per capire il task, ma Ã¨ l'hint che guida il comando da produrre.

- [x] `kiso/roles/worker.md`: aggiunta regola hint priority
- [x] `docs/llm-roles.md`: regola aggiunta in "Rules in the Default Prompt" per l'exec translator
- [x] `tests/test_brain.py`: `TestM47WorkerHintPriority` â€” test su presenza regola nel prompt

---

## Milestone 48: Prompt hygiene â€” ottimizzazioni trasversali ai role prompts

Ottimizzazioni identificate da revisione sistematica di tutti i role prompt. Nessun nuovo comportamento: solo coerenza, riduzione ridondanza, e colmare gap di istruzioni che il modello attualmente risolve per inferenza (con risultati variabili).

---

### 48a. Reviewer â€” "You receive" incoerente con il messaggio reale

**Problema**: il prompt descrive "You receive: The plan goal" ma da M47 il messaggio arriva etichettato `## Plan Context`. Il modello vede un'etichetta diversa da quella che il prompt descrive â€” incoerenza strutturale.

**Fix**: allineare la descrizione nel prompt a `Plan Context`.

- [x] `kiso/roles/reviewer.md`: "You receive: The plan goal" â†’ "The plan context"
- [x] `tests/test_brain.py`: `TestM48ReviewerPromptHygiene` â€” test_48a_you_receive_says_plan_context, test_48a_no_plan_goal_in_receive_block

---

### 48b. Reviewer â€” exit code non usato nelle regole

**Problema**: il reviewer riceve `## Command Status` (succeeded/FAILED exit code) ma nessuna regola dice come usarlo. Il modello lo interpreta autonomamente. In casi ambigui (output apparentemente ok ma exit code 1, o stderr con exit code 0) puÃ² sbagliare direzione senza istruzioni esplicite.

**Fix**: aggiungere regola esplicita: exit code non-zero Ã¨ un forte segnale di fallimento anche se l'output appare parzialmente ok; exit code 0 non Ã¨ sufficiente da solo se l'output non soddisfa l'`expect`.

- [x] `kiso/roles/reviewer.md`: aggiunta regola "Exit code is a strong signal: non-zero = forte indicatore di fallimento; zero = necessario ma non sufficiente"
- [x] `tests/test_brain.py`: `TestM48ReviewerPromptHygiene` â€” test_48b_exit_code_rule_present, test_48b_nonzero_is_failure_signal, test_48b_zero_not_sufficient_alone

---

### 48c. Planner â€” regole `expect` e `detail` frammentate

**Problema**: due coppie di regole concettualmente identiche sono spezzate e distanziate nel prompt:
1. Riga 21 (`expect non-null`) + riga 28 (`expect task-scoped`) â€” stessa regola in due pezzi
2. Riga 26 (`detail self-contained`) + riga 46 (`detail specific, include commands/paths`) â€” stessa istruzione ripetuta; la seconda (piÃ¹ importante) arriva ultima e viene letta con meno attenzione

**Fix**: unire ciascuna coppia in una regola sola, spostata in posizione rilevante. Riduce il testo totale del prompt.

- [x] `kiso/roles/planner.md`: regola expect unificata (non-null + task-scoped in una riga); regola detail unificata (self-contained + specific + commands/paths in una riga); rimossa riga ridondante "exec task detail must be specific"
- [x] `tests/test_brain.py`: `TestM48PlannerMergedRules` â€” 6 test su presenza regole unificate e assenza duplicati

---

### 48d. Curator â€” nessuna categoria nel promote

**Problema**: il curator promuove fatti come testo libero senza indicare la categoria (project/user/tool/general). L'informazione viene persa e il consolidator deve inferirla. Se il curator distinguesse giÃ  il tipo di fatto, la categorizzazione successiva sarebbe piÃ¹ affidabile.

**Fix**: aggiungere campo `category` al JSON di output del curator. `_apply_curator_result` usa la categoria per determinare il session scoping: solo `"user"` Ã¨ session-scoped, gli altri sono globali. Bug fix: i fatti non-user non devono piÃ¹ essere salvati con `session=session`.

- [x] `kiso/roles/curator.md`: aggiunta istruzione category per promote (project/user/tool/general)
- [x] `kiso/brain.py`: `CURATOR_SCHEMA` â€” aggiunto campo `category` nullable con enum; aggiunto a `required`
- [x] `kiso/brain.py`: `validate_curator` â€” validazione opzionale: se category != null, deve essere un valore valido
- [x] `kiso/worker/loop.py`: `_apply_curator_result` â€” usa `ev.get("category") or "general"`; session=session solo se category=="user", altrimenti session=None
- [x] `tests/test_brain.py`: `TestM48CuratorCategoryField` â€” 11 test su prompt, schema, validate_curator
- [x] `tests/test_worker.py`: `TestM48ApplyCuratorCategory` â€” 9 test su session scoping per ogni categoria

---

### 48e. Summarizer-facts â€” nessun tiebreaker per contraddizioni

**Problema**: il prompt dice "remove contradictory items" ma non specifica quale tenere quando due fatti si contraddicono. Il modello sceglie arbitrariamente.

**Fix**: aggiungere criterio esplicito di risoluzione: in caso di contraddizione, preferire il fatto con confidence piÃ¹ alta; se uguale, preferire il piÃ¹ specifico.

- [x] `kiso/roles/summarizer-facts.md`: aggiunta regola tiebreaker (higher confidence wins; if equal, more specific wins)
- [x] `tests/test_brain.py`: `TestM48SummarizerFactsTiebreaker` â€” 3 test su presenza regola tiebreaker

---

### 48f. Worker (exec translator) â€” nessuna regola su sudo

**Problema**: nessuna istruzione su `sudo`. In ambienti non-root, il planner puÃ² scrivere task detail che implicano privilegi elevati, e il worker aggiunge `sudo` autonomamente o non lo aggiunge â€” comportamento non deterministico.

**Fix**: aggiungere regola: non aggiungere `sudo` a meno che non sia esplicitamente menzionato nel task detail o nel system environment.

- [x] `kiso/roles/worker.md`: aggiunta regola "Do NOT add sudo unless explicitly mentioned"
- [x] `tests/test_brain.py`: `TestM48WorkerNoSudo` â€” 3 test su presenza regola no-sudo
- [x] `docs/llm-roles.md`: aggiornate sezioni Reviewer (exit code rule), Exec Translator (no-sudo), Curator (schema con category, verdicts), Summarizer-facts (tiebreaker)

---

## Milestone 49: Versioning â€” file versione + comando `kiso version`

**Problema**: la versione del progetto era implicita (solo in `pyproject.toml`). Non c'era un file canonico da usare come riferimento quando si scrive la versione in docs/devplan, nÃ© un comando CLI per stamparla.

**Fix**: file unico `kiso/_version.py` come source of truth + comando `kiso version` + flag `--version/-V`.

- [x] `kiso/_version.py`: `__version__ = "0.1.0"` â€” unica fonte di veritÃ  per la versione
- [x] `cli/__init__.py`: importa `__version__`; aggiunge `-V/--version` flag (argparse built-in); aggiunge `version` subcommand che stampa `kiso {__version__}`; descrizione parser include la versione
- [x] `tests/test_cli.py`: `TestVersionFile` (3 test: file exists, semver format, cli re-export) e `TestVersionCommand` (5 test: subcommand, print output, -V, --version, help includes version)

---

## Milestone 50: Multi-instance â€” named bots via Docker

**Contesto**: il wrapper `kiso-host.sh` esiste giÃ  e proxia i comandi al container. L'architettura Docker-native Ã¨ giÃ  il deployment model. M50 la estende per supportare piÃ¹ istanze named sulla stessa macchina.

**Principio**: ogni istanza Ã¨ un bot con un nome proprio (univoco). Il core non cambia â€” Ã¨ un'immagine Docker che non sa nulla di "istanze". Tutta la gestione Ã¨ nel wrapper host.

### Struttura dati locale

```
~/.kiso/
  instances.json            # { "jarvis": { "port": 8333 }, "work": { "port": 8334 } }
  instances/
    jarvis/                 # montato come /root/.kiso in kiso-jarvis
      config.toml
      .env
      kiso.db
      sessions/
      roles/
    work/
      ...
```

### Risoluzione istanza implicita

Se `--instance` non Ã¨ specificato:
- 0 istanze â†’ errore "Nessun bot configurato. Esegui: `kiso instance create NAME`"
- 1 istanza â†’ usata implicitamente (zero overhead per chi ha un solo bot)
- 2+ istanze â†’ errore "Specifica: `kiso --instance NAME`"

### Comandi

```bash
# Gestione istanze (nel wrapper host, non nel CLI Python)
kiso instance create NAME [--port N]   # init dir, docker run, registra in instances.json
kiso instance start NAME               # docker start kiso-{NAME}
kiso instance stop NAME                # docker stop kiso-{NAME}
kiso instance list                     # nome / porta / status (running|stopped)
kiso instance remove NAME [--yes]      # docker rm + cancella ~/.kiso/instances/{NAME}/
kiso instance logs NAME [-f]           # docker logs [-f] kiso-{NAME}
kiso instance restart NAME             # docker restart kiso-{NAME}

# Tutti i comandi esistenti ricevono --instance (opzionale, risolto implicitamente)
kiso [--instance NAME]                 # REPL
kiso [--instance NAME] msg "..."
kiso [--instance NAME] env set KEY VAL
kiso [--instance NAME] sessions
kiso [--instance NAME] skill install X
kiso [--instance NAME] reset session
```

### Comandi che spariscono

I comandi `kiso up`, `kiso down`, `kiso restart`, `kiso status`, `kiso logs`, `kiso shell`, `kiso explore` del wrapper corrente vengono assorbiti in `kiso instance *`. Non ha senso avere due interfacce per la stessa cosa.

### install.sh

Al primo install, `install.sh` chiede il nome del bot (default: `kiso`) e crea l'istanza di default. L'utente puÃ² usare `kiso` subito senza sapere nulla di istanze.

```bash
ðŸ¤– Come vuoi chiamare il tuo bot? [kiso]: jarvis
â†’ kiso instance create jarvis
â†’ kiso instance start jarvis
âœ“ Pronto. Esegui: kiso
```

### Modifiche al core (Python)

- `cli/__init__.py`: rimozione di `kiso serve` dal parser (il Dockerfile CMD cambia da `kiso serve` a `uvicorn` diretto)
- `cli/__init__.py`: rimozione dei comandi wrapper (`up`, `down`, `restart`, `status`, `logs`, `shell`, `explore`) se presenti nel parser Python â€” questi vivono solo nel wrapper bash
- Il resto del core non cambia

### Modifiche al Dockerfile

```dockerfile
# Prima:
CMD ["uv", "run", "kiso", "serve"]

# Dopo:
CMD ["uv", "run", "uvicorn", "kiso.server:app", "--host", "0.0.0.0", "--port", "8333"]
```

CosÃ¬ `kiso serve` puÃ² essere rimosso completamente senza rompere il container.

### Riferimenti da aggiornare

- `kiso-host.sh` â€” riscrittura completa per supporto multi-istanza
- `install.sh` â€” flusso di creazione istanza di default
- `Dockerfile` â€” CMD â†’ uvicorn diretto
- `docker-compose.yml` â€” aggiornato per multi-istanza (o rimosso se il wrapper lo gestisce)
- `docs/docker.md` â€” riscrittura completa (nuova architettura multi-bot)
- `docs/cli.md` â€” aggiornamento command reference (rimozione `serve`, aggiunta `instance *`)
- `docs/config.md` â€” path aggiornati (`~/.kiso/instances/{name}/` invece di `~/.kiso/`)
- `docs/connectors.md` â€” path aggiornati
- `docs/logging.md` â€” path aggiornati

### Subtask

- [ ] 50a. Core: rimozione `kiso serve` dal parser + Dockerfile CMD â†’ uvicorn
- [ ] 50b. Host wrapper: `kiso-host.sh` â€” multi-instance + risoluzione implicita
- [ ] 50c. install.sh: flusso creazione istanza di default
- [ ] 50d. Docs: aggiornamento completo di tutti i riferimenti

---

## Milestone 46: Plugin install â€” ask env vars before installing, with how-to instructions

**Problema osservato in produzione**: il planner installava il connettore discord, poi scopriva le env var mancanti dall'output di install, e solo alla fine chiedeva i valori all'utente. Doppio problema:
1. L'utente aspetta tutto il processo di install prima di essere interrogato.
2. Il messaggio all'utente non spiegava come ottenere i valori (dove trovare il bot token, cosa Ã¨ il kiso token, ecc.).

**Cause root**:
1. Il prompt del planner diceva "install, then check" â€” ordine sbagliato.
2. `kiso.toml` del connettore discord non aveva `description` nei campi env var.
3. `cli/connector.py` stampava solo `warning: VAR not set`, senza descrizione.

**Fix**:

- [x] `plugins/connector-discord/kiso.toml`: aggiunto campo `description` a ogni env var (`bot_token`, `kiso_token`, `webhook_secret`) con istruzioni su come ottenerli
- [x] `cli/connector.py`: `_connector_install()` â€” stampa `(required|optional) â€” {description}` accanto a ogni warning di env var mancante; usa `decl.items()` invece di `for key in env_decl` per accedere alle descrizioni
- [x] `kiso/roles/planner.md`: regola "Plugin installation (MANDATORY)" riscritta come lista ordinata di 6 step: (1) curl registry, (2) curl kiso.toml da GitHub PRIMA di installare, (3) msg user con descrizioni se env var mancanti, (4) kiso env set, (5) install, (6) run
- [x] `tests/test_cli_connector.py`: `test_connector_install_env_warning_includes_description` â€” verifica che l'output di install contenga la description accanto al warning per required e optional
- [x] `tests/test_brain.py`: `test_m46_plugin_install_checks_kiso_toml_before_install` â€” verifica che raw.githubusercontent.com/kiso.toml appaia prima di `kiso connector install` nel prompt
- [x] `tests/test_brain.py`: `test_m46_plugin_install_includes_env_description_in_msg` â€” verifica che il prompt istruisca il planner a includere le descrizioni nel messaggio all'utente
- [x] `kiso/roles/messenger.md`: aggiunta regola "verbatim" â€” le istruzioni di setup (comandi, URL, step-by-step) devono essere riportate esatte, non parafrasate
- [x] `tests/test_brain.py`: `test_verbatim_instructions_rule` â€” verifica che "verbatim" sia nel prompt del messenger

---
